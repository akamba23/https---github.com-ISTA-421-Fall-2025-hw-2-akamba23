---
title: "Homework 1"
author: "Mba Solomon Akachukwu."
date: "2025-09-12"
format: pdf
---

Question 1
a. The sample size (number of observations; n) is extremely large, and the number of
predictors (features; p) is small.

ANSWER: The flexible statistical learning is probably better because it doesn't have a lot of features, along with the
very large sample size. These would help combat overfitting.

b. The number of predictors (p) is extremely large, and the number of observations (n) is
small.

ANSWER: The inflexible statistical learning is better because a lot of features and not many data would make
it much easier for the data to overfit.

c. The relationship between the predictors and response is highly non-linear.

ANSWER: Flexible learning would work better because it is geared towards
covering patterns that are non linear.

d. ANSWER: The inflexible method is better because flexible method needs high variance, so using 
an inflexible method prevents that in order to avoid overfitting. 

Question 2
a. The curse of dimensionality is the problem where increasing the number of features (dimensions) in a dataset leads to data sparsity, exponential growth in data needed for accurate models, increased computational cost, and potential issues like overfitting and poor model performance. (Sources: GeeksForGeeks https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.geeksforgeeks.org/machine-learning/curse-of-dimensionality-in-machine-learning/&ved=2ahUKEwjB29vDstePAxW6le4BHeX9GWYQ-NANegUIIxCSAQ&usg=AOvVaw1bI8RMBCYno1Ghd8JAndwA Wikipedia https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://en.wikipedia.org/wiki/Curse_of_dimensionality%23:~:text%3DThe%2520curse%2520of%2520dimensionality%2520refers,grows%2520exponentially%2520with%2520the%2520dimensionality.&ved=2ahUKEwjB29vDstePAxW6le4BHeX9GWYQ-NANegUIIxCOAQ&usg=AOvVaw15ob8kTtAN85T6WeH1lSoW). 

b. Training error reduces as the complexity of the model increases, due to the fact that the model is a better fit with the data.
Test error begins to increase at one point because of overfitting.

c. Training datasets are a set of examples used to fit the parameters of the model. It is important to machine learning because it acts as the foundation upon which a model learns to identify patterns and make predictions. Test datasets are data sets used to provide unbiased evaluations of a final model fit on the training data set. They help in identifying overfitting. 